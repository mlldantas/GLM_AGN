<<<<<<< HEAD
as.mcmc.list(jags.logit, vars="Fit")[[1]][1,]
as.mcmc.list(jags.logit, vars="Fit")[[1]][1:10,]
as.mcmc.list(jags.logit, vars="Fit")[[1]]$Fit
as.mcmc.list(jags.logit, vars="Fit")[[1]][,1]
mean(as.mcmc.list(jags.logit, vars="Fit")[[1]][,1]<as.mcmc.list(jags.logit, vars="Fit")[[1]][,2])
plot(data.2$baryon_fraction,Pres)
>>>>>>> Stashed changes
setwd("~/Dropbox/artigos/Meusartigos/IAA-WGC/Github/Beta_regression")
#  JAGS script  Scape_Fraction.R
#  Copyright (C) 2015  Rafael S. de Souza
#
#This program is free software: you can redistribute it and/or modify
#it under the terms of the GNU General Public License version 3 as published by
#the Free Software Foundation.
#This program is distributed in the hope that it will be useful,
#but WITHOUT ANY WARRANTY; without even the implied warranty of
#MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#GNU General Public License for more details.
#  A copy of the GNU General Public License is available at
#  http://www.r-project.org/Licenses/
#
#  Required libraries
=======
qplot(months, temp, data=dtemp, group=city, color=city, geom="line") +
geom_point(size=1.1) +
theme_hc(bgcolor = "darkunica") +
scale_fill_hc("darkunica")
qplot(carat, price, data = dsamp, colour = cut)
+ theme_hc()
+ scale_colour_hc()
qplot(carat, price, data = dsamp, colour = cut)
+theme_hc()+scale_colour_hc()
qplot(carat, price, data = dsamp, colour = cut)+theme_hc()+scale_colour_hc()
qplot(carat, price, data = diamonds, colour = cut)+theme_hc()+scale_colour_hc()
qplot(carat, price, data = diamonds[1:100,], colour = cut)+theme_hc()+scale_colour_hc()
qplot(carat, price, data = diamonds[1:1000,], colour = cut)+theme_hc()+scale_colour_hc()
qplot(carat, price, data = diamonds, colour = cut)+theme_hc()+scale_colour_hc()
qplot(carat, price, data = diamonds, colour = cut)+theme_few()+scale_colour_hc()
qplot(carat, price, data = diamonds, colour = cut)+theme_few()+scale_colour_stata()
qplot(carat, price, data = diamonds, colour=clarity)+theme_few()+scale_colour_stata()
qplot(carat, price, data = diamonds[sample(nrow(diamonds), 1000), ], colour=clarity)+theme_few()+scale_colour_stata()
qplot(carat, price, data = diamonds[sample(nrow(diamonds), 1000), ], colour=clarity)+theme_few()+scale_colour_fivethirtyeight()
ggs_density(G1)+theme_few()+
theme(legend.position="none",plot.title = element_text(hjust=0.5),
axis.title.y=element_text(vjust=0.75),axis.text.x=element_text(size=18),
axis.text.y=element_text(size=18),
strip.text.x=element_text(size=25),
axis.title.x=element_text(vjust=-0.25),
text = element_text(size=20),axis.title.x=element_text(size=rel(1)))+
scale_colour_fivethirtyeight()
ggs_density(G1)+theme_few()+
theme(legend.position="none",plot.title = element_text(hjust=0.5),
axis.title.y=element_text(vjust=0.75),axis.text.x=element_text(size=18),
axis.text.y=element_text(size=18),
strip.text.x=element_text(size=25),
axis.title.x=element_text(vjust=-0.25),
text = element_text(size=20),axis.title.x=element_text(size=rel(1)))+
scale_colour_few()
ggs_density(G1)+theme_few()+
theme(legend.position="none",plot.title = element_text(hjust=0.5),
axis.title.y=element_text(vjust=0.75),axis.text.x=element_text(size=18),
axis.text.y=element_text(size=18),
strip.text.x=element_text(size=25),
axis.title.x=element_text(vjust=-0.25),
text = element_text(size=20),axis.title.x=element_text(size=rel(1)))
ggs_density(G1)+theme_few()+
theme(legend.position="none",plot.title = element_text(hjust=0.5),
axis.title.y=element_text(vjust=0.75),axis.text.x=element_text(size=18),
axis.text.y=element_text(size=18),
strip.text.x=element_text(size=25),
axis.title.x=element_text(vjust=-0.25),
text = element_text(size=20),axis.title.x=element_text(size=rel(1)))+
scale_colour_economist()
ggs_autocorrelation(G1)+theme_few()+
theme(legend.position="none",plot.title = element_text(hjust=0.5),
axis.title.y=element_text(vjust=0.75),axis.text.x=element_text(size=18),
axis.text.y=element_text(size=18),
strip.text.x=element_text(size=25),
axis.title.x=element_text(vjust=-0.25),
text = element_text(size=20),axis.title.x=element_text(size=rel(1)))+
scale_colour_economist()
ggs_autocorrelation(G1)+theme_few()+
theme(legend.position="none",plot.title = element_text(hjust=0.5),
axis.title.y=element_text(vjust=0.75),axis.text.x=element_text(size=18),
axis.text.y=element_text(size=18),
strip.text.x=element_text(size=25),
axis.title.x=element_text(vjust=-0.25),
text = element_text(size=20),axis.title.x=element_text(size=rel(1)))+
scale_colour_economist()+scale_fill_economist()
require(ggplot2)
#to get ggthemes from jrnold github if you have not installed
#require(devtools)
#install_github("ggthemes","jrnold")
require(ggthemes)
require(reshape2)
require(directlabels)
require(quantmod)
require(PerformanceAnalytics)
tckrs <- c("CSCO","MSFT","AAPL","^GSPC")
getSymbols(tckrs,from="1990-01-01")
prices <- na.omit(merge(CSCO[,6],MSFT[,6],AAPL[,6],GSPC[,6]))
colnames(prices) <- c("Cisco","Microsoft","Apple","SP500")
returns <- prices/lag(prices) - 1
returns[1,] <- 0
cumul <- cumprod(returns+1)
cumul.df <- as.data.frame(cbind(index(cumul),coredata(cumul)))
cumul.melt <- melt(cumul.df,id.vars=1)
colnames(cumul.melt) <- c("Date","Stock","Cumul")
cumul.melt[,"Date"] <- as.Date(cumul.melt[,"Date"])
direct.label(
ggplot(cumul.melt, aes(x=Date,y=log(Cumul),colour=Stock)) +
geom_line() +
theme_economist() +  #if you want to play try theme_wsj() or theme_few()
scale_colour_economist() +
ggtitle("Apple Compared to Others Since 1990")
, list(last.bumpup,hjust=0.45,cex=0.65))
direct.label(
ggplot(cumul.melt, aes(x=Date,y=log(Cumul),colour=Stock)) +
geom_line() +
theme_economist_white() +  #if you want to play try theme_wsj() or theme_few()
scale_colour_economist() +
ggtitle("Apple Compared to Others Since 1990")
, list(last.bumpup,hjust=0.45,cex=0.65))
#for reference I will use my old favorite theEconomist from latticeExtra
require(latticeExtra)
direct.label(
asTheEconomist(xyplot(log(Cumul)~Date,data=cumul.melt,groups=Stock,
main="Apple Compared to Microsoft and Cisco Since 1990")
)
, list(last.bumpup,hjust=0.25,cex=1))
install.packages("~/Downloads/rjags_4-3.tar", repos = NULL)
install.packages("~/Downloads/rjags_4-3.tar")
>>>>>>> origin/master
library(rjags)
library(ggmcmc)
library(ggplot2)
library(ggthemes)
library(pander)
library(Cairo)
library(plyr)
library(MASS)
library(scales)
<<<<<<< HEAD
library(plyr)
require(gdata)
require(runjags)
require(gdata)
require(caret)
require(pROC)
require(plyr)
#Read the  dataset
data.1= read.table(file="FiBY_escape_data_all.dat",header=FALSE)
colnames(data.1)<-c("redshift","fEsc","Mvir","Mstar","Mgas","QHI","sfr_gas",
"sfr_stars","ssfr_gas","ssfr_stars","baryon_fraction",
"spin","age_star_mean","age_star_max","age_star_min","NH_10")
trainIndex <- createDataPartition(data.1$redshift, p = .3,
list = FALSE,
times = 1)
#data.2<-data.1[data.1$redshift==8.86815,]
data.2<-data.1[trainIndex,]
#data.2<-data.1[data.1$redshift==8.86815,]
#data.2<-data.1
N<-nrow(data.2)
data.2$Y<-(data.2$fEsc*(N-1)+0.5)/N
data.2$Y[data.2$Y>=0.1]<-1
data.2$Y[data.2$Y<0.1]<-0
#data.2$Y<-as.factor(data.2$Y)
# Prepare data for JAGS
data.2$Mstar<-(data.2$Mstar-mean(data.2$Mstar))/sd(data.2$Mstar)
data.2$Mgas<-(data.2$Mgas-mean(data.2$Mgas))/sd(data.2$Mgas)
data.2$Mvir<-(data.2$Mvir-mean(data.2$Mvir))/sd(data.2$Mvir)
data.2$sfr_gas<-(data.2$sfr_gas-mean(data.2$sfr_gas))/sd(data.2$sfr_gas)
data.2$baryon_fraction<-(data.2$baryon_fraction-mean(data.2$baryon_fraction))/sd(data.2$baryon_fraction)
data.2$QHI<-(data.2$QHI-mean(data.2$QHI))/sd(data.2$QHI)
data.2$ssfr_gas<-(data.2$ssfr_gas-mean(data.2$ssfr_gas))/sd(data.2$ssfr_gas)
data.2$age_star_mean<-(data.2$age_star_mean-mean(data.2$age_star_mean))/sd(data.2$age_star_mean)
data.2$spin<-(data.2$spin-mean(data.2$spin))/sd(data.2$spin)
data.2$NH_10<-(data.2$NH_10-mean(data.2$NH_10))/sd(data.2$NH_10)
#X<-model.matrix(~Mvir+baryon_fraction+age_star_mean+ssfr_gas+NH_10+redshift,data=data.2)
X<-model.matrix(~QHI,data=data.2)
# Scale
K<-ncol(X)
jags.data <- list(Y= data.2$Y,
N = nrow(data.2),
X=X,
b0 = rep(0,K),
B0=diag(1e-4,K),
Npred = K
)
model<-"model{
#1. Priors
beta~dmnorm(b0[],B0[,]) # Normal Priors
# Jefreys priors for sparseness
#for(j in 1:Npred)   {
#      lnTau[j] ~ dunif(-50, 50)
#      TauM[j] <- exp(lnTau[j])
#      beta[j] ~ dnorm(0, TauM[j])
#     Ind[j] <- step(abs(beta[j]) - 0.05)
#}
#2. Likelihood
for(i in 1:N){
Y[i] ~ dbern(pi[i])
logit(pi[i]) <-  eta[i]
eta[i] <- inprod(beta[], X[i,])
#3. Prediction
NewPred[i]~dbern(pi[i])
}
}"
params <- c("beta","pi","NewPred")
inits0  <- function () {
list(beta = rnorm(K, 0, 0.1))}
inits1=inits0()
inits2=inits0()
inits3=inits0()
library(parallel)
cl <- makeCluster(6)
jags.logit <- run.jags(method="rjparallel",
data = jags.data,
inits = list(inits1,inits2,inits3),
model=model,
n.chains = 3,
adapt=1000,
monitor=c(params),
burnin=1000,
sample=5000,
summarise=FALSE,
plots=FALSE
)
jagssamples <- as.mcmc.list(jags.logit)
prediction<-summary(as.mcmc.list(jags.logit,vars="NewPred"))
prediction<-prediction$quantiles
probability<-summary(as.mcmc.list(jags.logit,vars="pi"))
prob<-probability$quantiles
ROC<-roc(prob[,3], data.2$Y)
plot(ROC)
jagssamples
fit=glm(Y~QHI,data=data.2,family="logit")
fit=glm(Y~QHI,data=data.2,family=binomial)
plot(fit)
curve(predict(fit,type="resp"),add=TRUE) # draws a curve based on prediction from logistic regression model
points(data.2$QHI,fitted(fit),pch=20)
curve(predict(fit,data.frame(data.2$QHI=x),type="resp"),add=TRUE) # draws a curve based on prediction from logistic regression model
points(data.2$QHI,fitted(fit),pch=20)
curve(predict(fit,data.frame(data.2$QHI=x),type="resp"),add=TRUE)
data.2$QHI
curve(predict(fit,data.frame(data.2$QHI),type="resp"),add=TRUE) # draws a curve based on prediction from logistic regression model
points(data.2$QHI,fitted(fit),pch=20)
curve(predict(fit,data.frame(x=data.2$QHI),type="resp"),add=TRUE) # draws a curve based on prediction from logistic regression model
points(data.2$QHI,fitted(fit),pch=20)
plot(y=predict(fit,type="resp"),x=data.2$QHI,add=TRUE) # draws a curve based on prediction from logistic regression model
points(data.2$QHI,fitted(fit),pch=20)
plot(y=predict(fit,type="resp"),x=data.2$QHI) # draws a curve based on prediction from logistic regression model
points(data.2$QHI,fitted(fit),pch=20)
plot(y=predict(fit,type="resp"),x=data.2$QHI)
plot(y=predict(fit,type="resp"),x=data.2$QHI) # draws a curve based on prediction from logistic regression model
points(data.2$QHI,data.2$Y,pch=20)
data.2$Y
plot(y=predict(fit,type="resp"),x=data.2$QHI) # draws a curve based on prediction from logistic regression model
points(data.2$QHI,data.2$Y,pch=20)
gdata<-as.data.frame(y=predict(fit,type="resp"),x=data.2$QHI)
gdata<-as.data.frame(pi=predict(fit,type="resp"),x=data.2$QHI,y=data.2$Y)
gdata<-as.data.frame(pi=predict(fit,type="resp"),x=data.2$QHI,y=data.2$Y)
ggplot(gdata,aes(x=x,y=pi))+geom_line()+geom_point(data=gdata,aes(x=data.2$QHI,y=data.2$Y)
)
ggplot(gdata,aes(x=x,y=pi))+geom_line()+geom_point(data=gdata,aes(x=x,y=y))
gdata
gdata[1,]
gdata<-data.frame(pi=predict(fit,type="resp"),x=data.2$QHI,y=data.2$Y)
gdata
ggplot(gdata,aes(x=x,y=pi))+geom_line()+geom_point(data=gdata,aes(x=x,y=y))
trainIndex <- createDataPartition(data.1$redshift, p = .4,
list = FALSE,
times = 1)
#data.2<-data.1[data.1$redshift==8.86815,]
data.2<-data.1[trainIndex,]
#data.2<-data.1[data.1$redshift==8.86815,]
#data.2<-data.1
N<-nrow(data.2)
data.2$Y<-(data.2$fEsc*(N-1)+0.5)/N
data.2$Y[data.2$Y>=0.1]<-1
data.2$Y[data.2$Y<0.1]<-0
#data.2$Y<-as.factor(data.2$Y)
# Prepare data for JAGS
data.2$Mstar<-(data.2$Mstar-mean(data.2$Mstar))/sd(data.2$Mstar)
data.2$Mgas<-(data.2$Mgas-mean(data.2$Mgas))/sd(data.2$Mgas)
data.2$Mvir<-(data.2$Mvir-mean(data.2$Mvir))/sd(data.2$Mvir)
data.2$sfr_gas<-(data.2$sfr_gas-mean(data.2$sfr_gas))/sd(data.2$sfr_gas)
data.2$baryon_fraction<-(data.2$baryon_fraction-mean(data.2$baryon_fraction))/sd(data.2$baryon_fraction)
#data.2$QHI<-(data.2$QHI-mean(data.2$QHI))/sd(data.2$QHI)
data.2$ssfr_gas<-(data.2$ssfr_gas-mean(data.2$ssfr_gas))/sd(data.2$ssfr_gas)
data.2$age_star_mean<-(data.2$age_star_mean-mean(data.2$age_star_mean))/sd(data.2$age_star_mean)
data.2$spin<-(data.2$spin-mean(data.2$spin))/sd(data.2$spin)
data.2$NH_10<-(data.2$NH_10-mean(data.2$NH_10))/sd(data.2$NH_10)
#X<-model.matrix(~Mvir+baryon_fraction+age_star_mean+ssfr_gas+NH_10+redshift,data=data.2)
X<-model.matrix(~QHI,data=data.2)
# Scale
K<-ncol(X)
jags.data <- list(Y= data.2$Y,
N = nrow(data.2),
X=X,
b0 = rep(0,K),
B0=diag(1e-4,K),
Npred = K
)
model<-"model{
#1. Priors
beta~dmnorm(b0[],B0[,]) # Normal Priors
# Jefreys priors for sparseness
#for(j in 1:Npred)   {
#      lnTau[j] ~ dunif(-50, 50)
#      TauM[j] <- exp(lnTau[j])
#      beta[j] ~ dnorm(0, TauM[j])
#     Ind[j] <- step(abs(beta[j]) - 0.05)
#}
#2. Likelihood
for(i in 1:N){
Y[i] ~ dbern(pi[i])
logit(pi[i]) <-  eta[i]
eta[i] <- inprod(beta[], X[i,])
#3. Prediction
NewPred[i]~dbern(pi[i])
}
}"
params <- c("beta","pi","NewPred")
inits0  <- function () {
list(beta = rnorm(K, 0, 0.1))}
inits1=inits0()
inits2=inits0()
inits3=inits0()
library(parallel)
cl <- makeCluster(6)
jags.logit <- run.jags(method="rjparallel",
data = jags.data,
inits = list(inits1,inits2,inits3),
model=model,
n.chains = 3,
adapt=1000,
monitor=c(params),
burnin=1000,
sample=5000,
summarise=FALSE,
plots=FALSE
)
fit=glm(Y~QHI,data=data.2,family="logit")
gdata<-data.frame(pi=predict(fit,type="resp"),x=data.2$QHI,y=data.2$Y)
ggplot(gdata,aes(x=x,y=pi))+geom_line()+geom_point(data=gdata,aes(x=x,y=y))
data.1= read.table(file="FiBY_escape_data_all.dat",header=FALSE)
colnames(data.1)<-c("redshift","fEsc","Mvir","Mstar","Mgas","QHI","sfr_gas",
"sfr_stars","ssfr_gas","ssfr_stars","baryon_fraction",
"spin","age_star_mean","age_star_max","age_star_min","NH_10")
trainIndex <- createDataPartition(data.1$redshift, p = .4,
list = FALSE,
times = 1)
#data.2<-data.1[data.1$redshift==8.86815,]
data.2<-data.1[trainIndex,]
#data.2<-data.1[data.1$redshift==8.86815,]
#data.2<-data.1
N<-nrow(data.2)
data.2$Y<-(data.2$fEsc*(N-1)+0.5)/N
data.2$Y[data.2$Y>=0.1]<-1
data.2$Y[data.2$Y<0.1]<-0
#data.2$Y<-as.factor(data.2$Y)
# Prepare data for JAGS
data.2$Mstar<-(data.2$Mstar-mean(data.2$Mstar))/sd(data.2$Mstar)
data.2$Mgas<-(data.2$Mgas-mean(data.2$Mgas))/sd(data.2$Mgas)
data.2$Mvir<-(data.2$Mvir-mean(data.2$Mvir))/sd(data.2$Mvir)
data.2$sfr_gas<-(data.2$sfr_gas-mean(data.2$sfr_gas))/sd(data.2$sfr_gas)
data.2$baryon_fraction<-(data.2$baryon_fraction-mean(data.2$baryon_fraction))/sd(data.2$baryon_fraction)
#data.2$QHI<-(data.2$QHI-mean(data.2$QHI))/sd(data.2$QHI)
data.2$ssfr_gas<-(data.2$ssfr_gas-mean(data.2$ssfr_gas))/sd(data.2$ssfr_gas)
data.2$age_star_mean<-(data.2$age_star_mean-mean(data.2$age_star_mean))/sd(data.2$age_star_mean)
data.2$spin<-(data.2$spin-mean(data.2$spin))/sd(data.2$spin)
data.2$NH_10<-(data.2$NH_10-mean(data.2$NH_10))/sd(data.2$NH_10)
fit=glm(Y~QHI,data=data.2,family="logit")
gdata<-data.frame(pi=predict(fit,type="resp"),x=data.2$QHI,y=data.2$Y)
fit=glm(Y~QHI,data=data.2,family=binomial)
gdata<-data.frame(pi=predict(fit,type="resp"),x=data.2$QHI,y=data.2$Y)
ggplot(gdata,aes(x=x,y=pi))+geom_line()+geom_point(data=gdata,aes(x=x,y=y))
library(popbio)
logi.hist.plot(data.2$QHI,data.2$Y,boxp=FALSE,type="hist",col="gray")
install.packages("popbio")
library(popbio)
logi.hist.plot(data.2$QHI,data.2$Y,boxp=FALSE,type="hist",col="gray")
trainIndex <- createDataPartition(data.1$redshift, p = .9,
list = FALSE,
times = 1)
#data.2<-data.1[data.1$redshift==8.86815,]
data.2<-data.1[trainIndex,]
#data.2<-data.1[data.1$redshift==8.86815,]
#data.2<-data.1
N<-nrow(data.2)
data.2$Y<-(data.2$fEsc*(N-1)+0.5)/N
data.2$Y[data.2$Y>=0.1]<-1
data.2$Y[data.2$Y<0.1]<-0
logi.hist.plot(data.2$QHI,data.2$Y,boxp=FALSE,type="hist",col="gray")
# Prepare data for JAGS
data.2$Mstar<-(data.2$Mstar-mean(data.2$Mstar))/sd(data.2$Mstar)
data.2$Mgas<-(data.2$Mgas-mean(data.2$Mgas))/sd(data.2$Mgas)
data.2$Mvir<-(data.2$Mvir-mean(data.2$Mvir))/sd(data.2$Mvir)
data.2$sfr_gas<-(data.2$sfr_gas-mean(data.2$sfr_gas))/sd(data.2$sfr_gas)
data.2$baryon_fraction<-(data.2$baryon_fraction-mean(data.2$baryon_fraction))/sd(data.2$baryon_fraction)
data.2$QHI<-(data.2$QHI-mean(data.2$QHI))/sd(data.2$QHI)
data.2$ssfr_gas<-(data.2$ssfr_gas-mean(data.2$ssfr_gas))/sd(data.2$ssfr_gas)
data.2$age_star_mean<-(data.2$age_star_mean-mean(data.2$age_star_mean))/sd(data.2$age_star_mean)
data.2$spin<-(data.2$spin-mean(data.2$spin))/sd(data.2$spin)
data.2$NH_10<-(data.2$NH_10-mean(data.2$NH_10))/sd(data.2$NH_10)
logi.hist.plot(data.2$QHI,data.2$Y,boxp=FALSE,type="hist",col="gray")
logi.hist.plot(data.2$baryon_fraction,data.2$Y,boxp=FALSE,type="hist",col="gray")
trainIndex <- createDataPartition(data.1$redshift, p = .9,
list = FALSE,
times = 1)
#data.2<-data.1[data.1$redshift==8.86815,]
data.2<-data.1[trainIndex,]
#data.2<-data.1[data.1$redshift==8.86815,]
#data.2<-data.1
N<-nrow(data.2)
data.2$Y<-(data.2$fEsc*(N-1)+0.5)/N
data.2$Y[data.2$Y>=0.1]<-1
data.2$Y[data.2$Y<0.1]<-0
#data.2$Y<-as.factor(data.2$Y)
logi.hist.plot(data.2$baryon_fraction,data.2$Y,boxp=FALSE,type="hist",col="gray")
data.1= read.table(file="FiBY_escape_data_all.dat",header=FALSE)
colnames(data.1)<-c("redshift","fEsc","Mvir","Mstar","Mgas","QHI","sfr_gas",
"sfr_stars","ssfr_gas","ssfr_stars","baryon_fraction",
"spin","age_star_mean","age_star_max","age_star_min","NH_10")
trainIndex <- createDataPartition(data.1$redshift, p = .9,
list = FALSE,
times = 1)
#data.2<-data.1[data.1$redshift==8.86815,]
data.2<-data.1[trainIndex,]
#data.2<-data.1[data.1$redshift==8.86815,]
#data.2<-data.1
N<-nrow(data.2)
data.2$Y<-(data.2$fEsc*(N-1)+0.5)/N
data.2$Y[data.2$Y>=0.1]<-1
data.2$Y[data.2$Y<0.1]<-0
#data.2$Y<-as.factor(data.2$Y)
logi.hist.plot(data.2$baryon_fraction,data.2$Y,boxp=FALSE,type="hist",col="gray")
data.2$baryon_fraction
data.1= read.table(file="FiBY_escape_data_all.dat",header=FALSE)
colnames(data.1)<-c("redshift","fEsc","Mvir","Mstar","Mgas","QHI","sfr_gas",
"sfr_stars","ssfr_gas","ssfr_stars","baryon_fraction",
"spin","age_star_mean","age_star_max","age_star_min","NH_10")
trainIndex <- createDataPartition(data.1$redshift, p = .9,
list = FALSE,
times = 1)
#data.2<-data.1[data.1$redshift==8.86815,]
data.2<-data.1[trainIndex,]
#data.2<-data.1[data.1$redshift==8.86815,]
#data.2<-data.1
N<-nrow(data.2)
data.2$Y<-(data.2$fEsc*(N-1)+0.5)/N
data.2$Y[data.2$Y>=0.1]<-1
data.2$Y[data.2$Y<0.1]<-0
logi.hist.plot(data.2$baryon_fraction,data.2$Y,boxp=FALSE,type="hist",col="gray")
data.2$baryon_fraction
logi.hist.plot(data.2$ssfr_gas,data.2$Y,boxp=FALSE,type="hist",col="gray")
logi.hist.plot(data.2$ssfr_stars,data.2$Y,boxp=FALSE,type="hist",col="gray")
logi.hist.plot(data.2$ssfr_gas,data.2$Y,boxp=FALSE,type="hist",col="gray")
logi.hist.plot(data.2$ssfr_gas,data.2$Y,boxp=T,type="hist",counts = T,col="gray",xlabel = expression(sSFR[gas]))
logi.hist.plot(data.2$ssfr_gas,data.2$Y,boxp=T,type="hist",counts = T,col="gray",xlabel = expression(sSFR[gas]),ylabel="Probability")
logi.hist.plot(data.2$ssfr_gas,data.2$Y,boxp=F,type="hist",counts = T,col="gray",xlabel = expression(sSFR[gas]),ylabel="Probability")
trainIndex <- createDataPartition(data.1$redshift, p = .9,
list = FALSE,
times = 1)
#data.2<-data.1[data.1$redshift==8.86815,]
data.2<-data.1[trainIndex,]
#data.2<-data.1[data.1$redshift==8.86815,]
#data.2<-data.1
N<-nrow(data.2)
data.2$Y<-(data.2$fEsc*(N-1)+0.5)/N
data.2$Y[data.2$Y>=0.5]<-1
data.2$Y[data.2$Y<0.5]<-0
logi.hist.plot(data.2$ssfr_gas,data.2$Y,boxp=F,type="hist",counts = T,col="gray",xlabel = expression(sSFR[gas]),ylabel="Probability")
logi.hist.plot(data.2$baryon_fraction,data.2$Y,boxp=F,type="hist",counts = T,col="gray",xlabel = expression(sSFR[gas]),ylabel="Probability")
trainIndex <- createDataPartition(data.1$redshift, p = .9,
list = FALSE,
times = 1)
#data.2<-data.1[data.1$redshift==8.86815,]
data.2<-data.1[trainIndex,]
#data.2<-data.1[data.1$redshift==8.86815,]
#data.2<-data.1
N<-nrow(data.2)
data.2$Y<-(data.2$fEsc*(N-1)+0.5)/N
data.2$Y[data.2$Y>=0.1]<-1
data.2$Y[data.2$Y<0.1]<-0
#data.2$Y<-as.factor(data.2$Y)
# Prepare data for JAGS
data.2$Mstar<-(data.2$Mstar-mean(data.2$Mstar))/sd(data.2$Mstar)
data.2$Mgas<-(data.2$Mgas-mean(data.2$Mgas))/sd(data.2$Mgas)
data.2$Mvir<-(data.2$Mvir-mean(data.2$Mvir))/sd(data.2$Mvir)
data.2$sfr_gas<-(data.2$sfr_gas-mean(data.2$sfr_gas))/sd(data.2$sfr_gas)
data.2$baryon_fraction<-(data.2$baryon_fraction-mean(data.2$baryon_fraction))/sd(data.2$baryon_fraction)
data.2$QHI<-(data.2$QHI-mean(data.2$QHI))/sd(data.2$QHI)
data.2$ssfr_gas<-(data.2$ssfr_gas-mean(data.2$ssfr_gas))/sd(data.2$ssfr_gas)
data.2$age_star_mean<-(data.2$age_star_mean-mean(data.2$age_star_mean))/sd(data.2$age_star_mean)
data.2$spin<-(data.2$spin-mean(data.2$spin))/sd(data.2$spin)
data.2$NH_10<-(data.2$NH_10-mean(data.2$NH_10))/sd(data.2$NH_10)
logi.hist.plot(data.2$baryon_fraction,data.2$Y,boxp=F,type="hist",counts = T,col="gray",xlabel = expression(sSFR[gas]),ylabel="Probability")
fit=glm(Y~QHI,data=data.2,family=binomial)
gdata<-data.frame(pi=predict(fit,type="resp"),x=data.2$QHI,y=data.2$Y)
ggplot(gdata,aes(x=x,y=pi))+geom_line()+geom_point(data=gdata,aes(x=x,y=y))
logi.hist.plot(data.2$baryon_fraction,data.2$Y,boxp=F,type="hist",counts = T,col="gray",xlabel = expression(sSFR[gas]),ylabel="Probability")
setwd("~/Dropbox/artigos/Meusartigos/IAA-WGC/Github/Beta_regression")
#  JAGS script  Scape_Fraction.R
#  Copyright (C) 2015  Rafael S. de Souza
#
#This program is free software: you can redistribute it and/or modify
#it under the terms of the GNU General Public License version 3 as published by
#the Free Software Foundation.
#This program is distributed in the hope that it will be useful,
#but WITHOUT ANY WARRANTY; without even the implied warranty of
#MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#GNU General Public License for more details.
#  A copy of the GNU General Public License is available at
#  http://www.r-project.org/Licenses/
#
#  Required libraries
=======
library(rjags)
install.packages("rjags")
library(rjags)
library(ggmcmc)
library(ggplot2)
library(ggthemes)
library(pander)
library(Cairo)
library(plyr)
library(MASS)
library(scales)
# Read data
data<-read.csv("..//data/M_sigma.csv",header = T,sep="")
# Prepare data
Msigma<-data.frame(x=log(data$sig_e/200,10),y=data$MBH)
Msigma2<-na.omit(Msigma) # remove NAs
Msigma2<-Msigma2[Msigma2$y>0,] # remove data with MBH=0
# Prepare data to JAGS
jags.data <- list(
x = Msigma2$x,
y = Msigma2$y,
N = nrow(Msigma2)
)
# Normal Model
model.normal<-"model{
#Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dt(0,1,1)
tau~dgamma(1e-3,1e-3)
scat<-1/sqrt(tau)
# Likelihood function
for (i in 1:N){
mu[i]<-beta.0+beta.1*x[i]
y[i]~dnorm(mu[i],tau)
#
# Prediction
prediction[i]~dnorm(mu[i],tau)
}
}"
#inits<-list(beta.0=coefficients(glm.pois)[1],beta.1=coefficients(glm.pois)[2])
inits<-list(beta.0=0,beta.1=0)
params<-c("beta.0","beta.1","scat")
jags.normal<-jags.model(
data = jags.data,
inits = inits,
textConnection(model.normal),
n.chains = 3,
n.adapt=1000
)
update(jags.normal, 5000)
posterior.normal <- coda.samples(jags.normal, params, n.iter = 20000)
#inits<-list(beta.0=coefficients(glm.pois)[1],beta.1=coefficients(glm.pois)[2])
inits<-list(beta.0=0,beta.1=0)
params<-c("beta.0","beta.1","scat")
jags.normal<-jags.model(
data = jags.data,
inits = inits,
textConnection(model.normal),
n.chains = 3,
n.adapt=1000
)
update(jags.normal, 5000)
posterior.normal <- coda.samples(jags.normal, params, n.iter = 20000)
#inits<-list(beta.0=coefficients(glm.pois)[1],beta.1=coefficients(glm.pois)[2])
inits<-list(beta.0=0,beta.1=0)
params<-c("beta.0","beta.1","scat")
jags.normal<-jags.model(
data = jags.data,
inits = inits,
textConnection(model.normal),
n.chains = 3,
n.adapt=1000
)
update(jags.normal, 5000)
posterior.normal <- coda.samples(jags.normal, params, n.iter = 20000)
library(rjags)
install.packages("~/Downloads/rjags_4-3-2.tar", repos = NULL)
install.packages("~/Downloads/rjags_4-3-2.tar")
install.packages("~/Downloads/rjags_4-3-2.tar",type="source")
install.packages("~/Downloads/rjags_4-3-2.tar", repos = NULL)
install.packages("~/Downloads/rjags_4-3-2.tar", type="source")
install.packages("~/Downloads/rjags_4-3-2.tar", type="source",repos=NULL)
library("rjags", lib.loc="~/Library/R/3.2/library")
install.packages("~/Downloads/rjags_4-3-2.tar", type="source",repos=NULL,dependencies=TRUE)
library("rjags", lib.loc="~/Library/R/3.2/library")
install.packages("rjags")
library(rjags)
library(ggmcmc)
library(ggplot2)
library(ggthemes)
library(pander)
library(Cairo)
library(plyr)
library(MASS)
library(scales)
# Read data
data<-read.csv("..//data/M_sigma.csv",header = T,sep="")
# Prepare data
Msigma<-data.frame(x=log(data$sig_e/200,10),y=data$MBH)
Msigma2<-na.omit(Msigma) # remove NAs
Msigma2<-Msigma2[Msigma2$y>0,] # remove data with MBH=0
# Prepare data to JAGS
jags.data <- list(
x = Msigma2$x,
y = Msigma2$y,
N = nrow(Msigma2)
)
# Normal Model
model.normal<-"model{
#Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dt(0,1,1)
tau~dgamma(1e-3,1e-3)
scat<-1/sqrt(tau)
# Likelihood function
for (i in 1:N){
mu[i]<-beta.0+beta.1*x[i]
y[i]~dnorm(mu[i],tau)
#
# Prediction
prediction[i]~dnorm(mu[i],tau)
}
}"
#inits<-list(beta.0=coefficients(glm.pois)[1],beta.1=coefficients(glm.pois)[2])
inits<-list(beta.0=0,beta.1=0)
params<-c("beta.0","beta.1","scat")
jags.normal<-jags.model(
data = jags.data,
inits = inits,
textConnection(model.normal),
n.chains = 3,
n.adapt=1000
)
update(jags.normal, 5000)
posterior.normal <- coda.samples(jags.normal, params, n.iter = 20000)
library(rjags)
install.packages("~/Downloads/rjags_4-3-2.tar",type="source")
install.packages("rjags")
>>>>>>> origin/master
library(rjags)
library(ggmcmc)
library(ggplot2)
library(ggthemes)
library(pander)
library(Cairo)
library(plyr)
library(MASS)
library(scales)
<<<<<<< HEAD
library(plyr)
require(gdata)
require(runjags)
require(gdata)
require(caret)
require(pROC)
require(plyr)
data.1= read.table(file="FiBY_escape_data_all.dat",header=FALSE)
colnames(data.1)<-c("redshift","fEsc","Mvir","Mstar","Mgas","QHI","sfr_gas",
"sfr_stars","ssfr_gas","ssfr_stars","baryon_fraction",
"spin","age_star_mean","age_star_max","age_star_min","NH_10")
trainIndex <- createDataPartition(data.1$redshift, p = .9,
list = FALSE,
times = 1)
#data.2<-data.1[data.1$redshift==8.86815,]
data.2<-data.1[trainIndex,]
#data.2<-data.1[data.1$redshift==8.86815,]
#data.2<-data.1
N<-nrow(data.2)
library(popbio)
logi.hist.plot(data.2$baryon_fraction,data.2$Y,boxp=F,type="hist",counts = T,col="gray",xlabel = expression(sSFR[gas]),ylabel="Probability")
data.2$Y<-(data.2$fEsc*(N-1)+0.5)/N
data.2$Y[data.2$Y>=0.1]<-1
data.2$Y[data.2$Y<0.1]<-0
library(popbio)
logi.hist.plot(data.2$baryon_fraction,data.2$Y,boxp=F,type="hist",counts = T,col="gray",xlabel = expression(sSFR[gas]),ylabel="Probability")
runif(10,0,100)
x<-runif(10,0,100)
x/sum(x)
sum(x/sum(x))
x<-runif(10,0,100)
x2<-x/sum(x)
sum(x2)
x2<-100Â°x/sum(x)
sum(x2)
x<-runif(10,0,100)
x2<-100*x/sum(x)
sum(x2)
setwd("~/Dropbox/artigos/Meusartigos/IAA-WGC/Github/GLM_AGN/script")
# Logit regression with AGNs
require(arm)
require(plyr)
library(caret)
library(pROC)
AGN_data<-read.table("../data/outputdata.txt",header=TRUE,sep="")
AGN_data$WHAN_Class<-as.factor(AGN_data$WHAN_Class)
AGN_data$WHAN_Class<-revalue(AGN_data$WHAN_Class,c("2"="1","3"="1","1"="0","4"="0"))
fit<-bayesglm(WHAN_Class~log10.NII.Ha.+log10.EW.Ha..,family=binomial(link="logit"),scaled=TRUE,
data = AGN_data)
ROCF<- data.frame(True=AGN_data$WHAN_Class,predicted=predict(fit,type = "response"))
F1 <-roc(ROCF$True,ROCF$predicted)
coords(F1,x="best")[1]
ROCF$class<-ROCF$predicted
ROCF$class[which(ROCF$class>=coords(F1,x="best")[1])]<-1
ROCF$class[which(ROCF$class<coords(F1,x="best")[1])]<-0
confusionMatrix(ROCF$True, ROCF$class)
x <-range(AGN_data$log10.NII.Ha.)
x <- seq(x[1], x[2], length.out=50)
y <- range(AGN_data$log10.EW.Ha..)
y <- seq(y[1], y[2], length.out=50)
z <- outer(x,y,
function(log10.NII.Ha.,log10.EW.Ha..)
predict(fit, data.frame(log10.NII.Ha.,log10.EW.Ha..),type = 'response'))
library(rsm)
library(lattice)
YlOrBr <- c("#FFFFD4", "#FED98E", "#FE9929", "#D95F0E", "#993404")
#p<-persp(x,y,z, theta=150, phi=20,
#         expand = 0.5,shade = 0.1,
#         xlab="Z", ylab=expression(NII.Ha), zlab=expression(log10.EW.Ha),ticktype='detailed',
#         col = YlOrBr,border=NA,xlog=T,ylog=T)
#cor = topo.colors(200)
trellis.par.set("axis.line",list(axis.text=list(cex=20),col=NA,lty=1,lwd=2))
par(mar=c(1,1,1,1))
wireframe(z~x+y,data=data.frame(x=x, y=rep(y, each=length(x)), z=z),
par.settings = list(regions=list(alpha=0.4)),
col.regions =cor,drape=T,light.source = c(5,5,5),colorkey = FALSE,
xlab=list(label=expression(log10.NII.Ha.),cex=1.25), ylab=list(label=expression(log10.EW.Ha..),cex=1.25),
zlab=list(rot=90,label=expression(pi),cex=1.25,dist=-1,rot=0),
scale=list(tck=0.75,arrows=FALSE,distance =c(0.75, 0.75, 0.75)))
setwd("~/Dropbox/artigos/Meusartigos/IAA-WGC/Github/WHAN_Clustering/script")
=======
# Read data
data<-read.csv("..//data/M_sigma.csv",header = T,sep="")
# Prepare data
Msigma<-data.frame(x=log(data$sig_e/200,10),y=data$MBH)
Msigma2<-na.omit(Msigma) # remove NAs
Msigma2<-Msigma2[Msigma2$y>0,] # remove data with MBH=0
# Prepare data to JAGS
jags.data <- list(
x = Msigma2$x,
y = Msigma2$y,
N = nrow(Msigma2)
)
# Normal Model
model.normal<-"model{
#Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dt(0,1,1)
tau~dgamma(1e-3,1e-3)
scat<-1/sqrt(tau)
# Likelihood function
for (i in 1:N){
mu[i]<-beta.0+beta.1*x[i]
y[i]~dnorm(mu[i],tau)
#
# Prediction
prediction[i]~dnorm(mu[i],tau)
}
}"
#inits<-list(beta.0=coefficients(glm.pois)[1],beta.1=coefficients(glm.pois)[2])
inits<-list(beta.0=0,beta.1=0)
params<-c("beta.0","beta.1","scat")
jags.normal<-jags.model(
data = jags.data,
inits = inits,
textConnection(model.normal),
n.chains = 3,
n.adapt=1000
)
update(jags.normal, 5000)
posterior.normal <- coda.samples(jags.normal, params, n.iter = 20000)
install.packages("coda")
jags.normal<-jags.model(
data = jags.data,
inits = inits,
textConnection(model.normal),
n.chains = 3,
n.adapt=1000
)
update(jags.normal, 5000)
posterior.normal <- coda.samples(jags.normal, params, n.iter = 20000)
library(rjags)
library(ggmcmc)
library(ggplot2)
library(ggthemes)
library(pander)
library(Cairo)
library(plyr)
library(MASS)
library(scales)
# Read data
data<-read.csv("..//data/M_sigma.csv",header = T,sep="")
# Prepare data
Msigma<-data.frame(x=log(data$sig_e/200,10),y=data$MBH)
Msigma2<-na.omit(Msigma) # remove NAs
Msigma2<-Msigma2[Msigma2$y>0,] # remove data with MBH=0
# Prepare data to JAGS
jags.data <- list(
x = Msigma2$x,
y = Msigma2$y,
N = nrow(Msigma2)
)
# Normal Model
model.normal<-"model{
#Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dt(0,1,1)
tau~dgamma(1e-3,1e-3)
scat<-1/sqrt(tau)
# Likelihood function
for (i in 1:N){
mu[i]<-beta.0+beta.1*x[i]
y[i]~dnorm(mu[i],tau)
#
# Prediction
prediction[i]~dnorm(mu[i],tau)
}
}"
#inits<-list(beta.0=coefficients(glm.pois)[1],beta.1=coefficients(glm.pois)[2])
inits<-list(beta.0=0,beta.1=0)
params<-c("beta.0","beta.1","scat")
jags.normal<-jags.model(
data = jags.data,
inits = inits,
textConnection(model.normal),
n.chains = 3,
n.adapt=1000
)
update(jags.normal, 5000)
posterior.normal <- coda.samples(jags.normal, params, n.iter = 20000)
library(coda)
#inits<-list(beta.0=coefficients(glm.pois)[1],beta.1=coefficients(glm.pois)[2])
inits<-list(beta.0=0,beta.1=0)
params<-c("beta.0","beta.1","scat")
jags.normal<-jags.model(
data = jags.data,
inits = inits,
textConnection(model.normal),
n.chains = 3,
n.adapt=1000
)
setwd("~/Dropbox/artigos/Meusartigos/IAA-WGC/Github/Logit_Mar/script")
# JAGS Code with Adaptive Shrinkage
#  Required libraries
library(rjags);library(ggmcmc);library(ggplot2);library(ggthemes);library(pander);library(Cairo);library(MASS);library(parallel)
library(scales);library(plyr);require(gdata);require(runjags);require(gdata);require(caret);require(pROC);require(plyr)
cl       <- makeCluster(3) # For parallel computing
# Read and format data
data     <- read.csv("..//data/sample_CRP02_sub.csv",header=TRUE,na.strings="")
data[1,]
x<-1
GC_data['x'] <- list(x)
C_data <- vector(mode='list', length = 4)
GC_data <- vector(mode='list', length = 4)
names(GC_data) <- c('n','x','y','k')
GC_data['n'] <- nrow('y')
GC_data['x'] <- list(x)
GC_data
mode(x)
x<-lis(1,21,3)
x<-list(1,21,3)
GC_data['x'] <- x
GC_data['x'] <- list(x)
GC_data['x']
GC_data['x'] <- as.matrix(x)
GC_data['x'] <- as.data.frame(x)
x<-matrix(1,1,1,1,1,1,nrow=2,ncol=2)
x<-matrix(1,1,1,1,nrow=2,ncol=2)
x<-matrix(1,1,1,1,1),nrow=2,ncol=2)
x<-matrix(c(1,1,1,1,1),nrow=2,ncol=2)
matrix(c(1,2,3, 11,12,13), nrow = 2, ncol = 3, byrow = TRUE,
dimnames = list(c("row1", "row2"),
c("C.1", "C.2", "C.3")))
x<-matrix(c(1,2,3, 11,12,13), nrow = 2, ncol = 3, byrow = TRUE,
dimnames = list(c("row1", "row2"),
c("C.1", "C.2", "C.3")))
x
GC_data['x'] <- x
as.data.frame(x)
mode(x)
GC_data['x'] <- x
GC_data
GC_data$x<-x
GC_data
GC_data$x
GC_data <- vector(mode='list', length = 4)
GC_data
GC_data <- vector(mode='list', length = 4)
names(GC_data) <- c('n','x','y','k')
GC_data
Malu_dataset <- read.csv("~/Downloads/Malu_dataset.txt", sep="")
View(Malu_dataset)
GC_data <- vector(mode='list', length = 4)
names(GC_data) <- c('n','x','y','k')
x<-Malu_dataset
x
x[1,]
x<-x[,c("mag_ab_g", "mag_ab_r", "mag_ab_i","mag_ab_z")]
x
x[1:10,]
y<-x[,6]
y<-Malu_dataset[,6]
y
nrow(y)
GC_data$n <- as.data.frame(y)
GC_data$x <- x
GC_data$y <- list(y)
GC_data$k <- ncol(x)
GC_data
dim(GC_data$y)
GC_data$y
str(GC_data$y)
str(GC_data)
as.numeric(GC_data$y)
as.data.frameGC_data$y
as.data.frame(GC_data$y
)
GC_data$y <- y
as.data.frame(GC_data$y)
mode(y)
library(rstan)
call <- function(x, y, niter=150, warmup=50, chains = 3, model_name = 'lasso') {
#Takes in columns x (independent) and y (dependent), then returns a pystan object with the solution from LASSO.
# --IN--
# x - n by k matrix
# y - n by 1 column
# niter - total number of iterations
# warmup - total amount of warmup iterations (out of total iterations)
# chains - MCMC chains
#--OUT--
# file - pystan object containing results.
GC_data <- vector(mode='list', length = 4)
names(GC_data) <- c('n','x','y','k')
GC_data$n <- as.data.frame(y)
GC_data$x <- x
GC_data$y <- y
GC_data$k <- ncol(x)
#if (e != None){
# print('Errors are not implimented yet.')
#}
modeldir <- '../stan_models/'
modelname <- paste(modeldir,model_name, sep = '')
model <- readChar(modelname,file.info(modelname)$size)
return(stan(model_code = model, data = GC_data, iter = niter, warmup = warmup, chains = chains))
}
call <- function(x, y, niter=150, warmup=50, chains = 3, model_name = 'lasso') {
#Takes in columns x (independent) and y (dependent), then returns a pystan object with the solution from LASSO.
# --IN--
# x - n by k matrix
# y - n by 1 column
# niter - total number of iterations
# warmup - total amount of warmup iterations (out of total iterations)
# chains - MCMC chains
#--OUT--
# file - pystan object containing results.
GC_data <- vector(mode='list', length = 4)
names(GC_data) <- c('n','x','y','k')
GC_data$n <- as.data.frame(y)
GC_data$x <- x
GC_data$y <- y
GC_data$k <- ncol(x)
#if (e != None){
# print('Errors are not implimented yet.')
#}
modeldir <- '../stan_models/'
modelname <- paste(modeldir,model_name, sep = '')
model <- readChar(modelname,file.info(modelname)$size)
return(stan(model_code = model, data = GC_data, iter = niter, warmup = warmup, chains = chains))
}
setwd("~/Dropbox/artigos/Meusartigos/IAA-WGC/Github/GLM_AGN/script")
>>>>>>> origin/master
require(plyr)
library(caret)
require(kernlab)
library(e1071)
require(MASS)
require(mclust)
<<<<<<< HEAD
AGN_data<-read.table("../data/sample_WHAN_BPT_rafa.dat",header=F,sep="")
AGN_data[1,]
WHAN<-AGN_data[,c(9,10,11)]
WHAN$WHAN_Class<-as.factor(WHAN$WHAN_Class)
colnames(WHAN)<-c("x_WHAN","y_WHAN","class_WHAN")
WHAN$class_WHAN<-as.factor(WHAN$class_WHAN)
WHAN[1,]
plot(x_WHAN,y_WHAN,data=WHAN)
plot(WHAN$x_WHAN,WHAN$y_WHAN)
plot(WHAN$x_WHAN,WHAN$y_WHAN,xlim=c(-1.5,0.5),ylim=c(-0.5,2))
plot(WHAN$x_WHAN,WHAN$y_WHAN)
=======
AGN_data<-read.table("../data/outputdata_all.txt",header=TRUE,sep="")
AGN_data[1,]
>>>>>>> origin/master
